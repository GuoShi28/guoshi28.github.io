<!doctype html>
<html>

<head>
<title>Shi GUO</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Shi GUO, The Department of Computing, Hong Kong Polytechnic University"> 
<meta name="description" content="Shi GUO's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137722442-1', 'auto');
  ga('send', 'pageview');
</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">

<img src="./assets/img/image.jpg" style="float:right; margin-top:30px; width: 20%;border-radius: 5px;" />
<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1> Shi GUO <h1>
				</div>

                <h3>Young Researcher</h3>

				<p>
                    Shanghai AI Laboratory</br>
				</p>
				<p >
					<a href="mailto:guoshi@pjlab.org.cn">Email</a> &nbsp;/&nbsp;
					<a href="">CV</a> &nbsp;/&nbsp;
					<a href="https://scholar.google.com/citations?user=5hsEmuQAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
					<a href="https://github.com/GuoShi28/">Github</a>
				  </p>
			</td>
		<tr>
	</tbody>
</table>

<h2>Short Bio</h2> 

<p>
	I am a Young Researcher at <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>.
	I obtain my PhD degree at the Department of Computing, Hong Kong Polytechnic University supervised by <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Prof. Lei Zhang</a>.
	I have received my Master degree at school of Computer Science and Technology, Harbin Institute of Technology, supervised by <a href="https://homepage.hit.edu.cn/wangmengzuo">Prof. Wangmeng Zuo</a>.
	I also received my Bachelor degree in the Honors School from Harbin Institute of Technology majoring in Automation.
</p>


<h2> Selected Publications </h2>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">

<td style="padding:0px;width:20%;vertical-align:top">
	<div class="one">
		<div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
		<source src="./assets/img/2025-4DSloMo.mp4" type="video/mp4" style="box-shadow: 2px 2px 2px 2px rgba(0, 0, 0, 0.4);object-fit: cover; border-radius: 10px;">
		Your browser does not support the video tag.
		</video></div>
		<img src='./assets/img/2025-4DSloMo.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	</div>
	<script type="text/javascript">
		function smerf_start() {
		document.getElementById('smerf_image').style.opacity = "1";
		}

		function smerf_stop() {
		document.getElementById('smerf_image').style.opacity = "0";
		}
		smerf_stop()
	</script>
	</td>
<td style="padding:40px 20px 40px 0px;width:20%;vertical-align:middle">

	<span class="papertitle">4DSloMo: 4D Reconstruction for High Speed Scene with Asynchronous Capture</span>
	<br>
	<a href="https://yutian10.github.io/">Yutian Chen</a>,
	<strong>Shi Guo</strong>,
	<a href="https://tianshuoy.github.io">Tianshuo Yang</a>,
	<a href="https://dinglihe.github.io">Lihe Ding</a>,
	<a href="">Xiuyuan Yu</a>,
	<a href="https://www.gujinwei.org/">Jinwei Gu</a>,
	<a href="https://tianfan.info/">Tianfan Xue</a>
	
	<br>
	ACM SIGGRAPH Asia, 2025
	<br>
	<a href="https://openimaginglab.github.io/4DSloMo/">Project page</a>
	/
	<a href="https://arxiv.org/pdf/2507.05163">Paper</a>
	/
	<a href="https://github.com/OpenImagingLab/4DSloMo">Code (Coming soon)</a>
	<p>Our method can reconstruct high speed and complex 4D motion with high quality.</p>	
</td>
</tr>


<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
		<div class="one">
		<img src='./assets/img/2025-UltraFusion.jpg' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
		</div>
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion</span>
		<br>
		<a href="https://scholar.google.com/citations?user=pwixOhcAAAAJ&hl=zh-CN">Zixuan Chen*</a>,
		<a>Yujin Wang*</a>,
		<a href="https://caixin98.github.io/">Xin Cai</a>,
		<a href="https://zhiyuanyou.github.io/">Zhiyuan You</a>,
		<a href="https://openreview.net/profile?id=%7EZhe-Ming_Lu1">Zheming Lu</a>,
		<a>Fan Zhang</a>,
		<strong>Shi Guo</strong>,
		<a href="https://tianfan.info/">Tianfan Xue†</a>,
		
		<br>
		<em>CVPR (Highlight), 2025</em>, 2025
		<br>
		<a href="https://ultrafusion.intern-ai.org.cn/home">Website</a>
		/
		<a href="https://openimaginglab.github.io/UltraFusion/">Project page</a>
		/
		<a href="https://arxiv.org/abs/2501.11515">Paper</a>
		/
		<a href="https://github.com/OpenImagingLab/UltraFusion">Code</a>
		<p><em style="color:black;">We propose UltraFusion, the first exposure fusion technique that can merge input with 9 stops differences.</em></p>	
	</td>
	</tr>


<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
<td style="padding:0px;width:20%;vertical-align:top">
	<div class="one">
	<img src='./assets/img/2024-EVSHDR.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	</div>
</td>
<td style="padding:0px;width:80%;vertical-align:top">
	<span class="papertitle">Event-assisted 12-stop HDR Imaging of Dynamic Scene</span>
	<br>
	<strong>Shi Guo </strong>
	<a href="https://scholar.google.com.hk/citations?user=pwixOhcAAAAJ&hl=ja&oi=sra">Zixuan Chen</a>,
	<a href="https://naturezhanghn.github.io/">Ziran Zhang</a>,
	<a href="https://yutian10.github.io/">Yutian Chen</a>,
	<a href="https://gangweix.github.io/">Gangwei Xu</a>,
	<a href="https://tianfan.info/">Tianfan Xue</a>
	
	<br>
	<em>arXiv</em>, 2024
	<br>
	<a href="https://openimaginglab.github.io/Event-Assisted-12stops-HDR/">Project page</a>
	/
	<a href="https://arxiv.org/abs/2412.14705">Paper</a>
	/
	<a href="https://github.com/OpenImagingLab/Event-Assisted-12stops-HDR">Code (Coming soon)</a>
	<p><em style="color:black;">Using event camera, our method present the first attempt at 12-stop HDR imaging for dynamic scenes.</em></p>	
</td>
</tr>


<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
<td style="padding:0px;width:20%;vertical-align:top">
	<div class="one">
	<img src='./assets/img/2024-SigAsia-EventSelf.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	</div>
</td>
<td style="padding:0px;width:80%;vertical-align:top">
	<span class="papertitle">From Sim-to-Real: Toward General Event-based Low-Light Frame Interpolation with Per-scene Optimization</span>
	<br>
	<a href="https://naturezhanghn.github.io/">Ziran Zhang*</a>,
	<a href="https://scholar.google.com/citations?user=JwQLEocAAAAJ&hl=en">Yongrui Ma*</a>,
	<a href="https://scholar.google.com/citations?user=gS-0tfAAAAAJ&hl=en">Yueting Chen</a>,
	<a href="">Feng Zhang</a>,
	<a href="https://www.gujinwei.org/">Jinwei Gu</a>,
	<a href="https://tianfan.info/">Tianfan Xue†</a>,
	<strong>Shi Guo† </strong>
	
	<br>
	<em>ACM SIGGRAPH Asia</em>, 2024
	<br>
	<a href="https://openimaginglab.github.io/Sim2Real/">Project page</a>
	/
	<a href="https://www.youtube.com/watch?v=PiYEh_zcG88">Video</a>
	/
	<a href="https://arxiv.org/pdf/2406.08090">Paper</a>
	/
	<a href="https://github.com/OpenImagingLab/Sim2Real">Code</a>
	<p><em style="color:black;">Toward General Event-based Low-Light Frame Interpolation.</em></p>	
</td>
</tr>

<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2024-motion-mag-evs.gif' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">Event-Based Motion Magnification</span>
	  <br>
	  <a href="https://yutian10.github.io/">Yutian Chen</a>,
	  <strong>Shi Guo† </strong>,
	  <a href="">Fangzheng Yu</a>,
	  <a href="">Feng Zhang</a>,
	  <a href="https://www.gujinwei.org/">Jinwei Gu</a>,
	  <a href="https://tianfan.info/">Tianfan Xue</a>
	  
	  <br>
	  <em>ECCV</em>, 2024
	  <br>
	  <a href="https://openimaginglab.github.io/emm/">Project page</a>
	  /
	  <a href="https://youtu.be/WmI7bv9nqjI">Video</a>
	  /
	  <a href="https://arxiv.org/pdf/2402.11957.pdf">Paper</a>
	  /
	  <a href="https://github.com/OpenImagingLab/emm">Code</a>
	  <p><em style="color:black;">Broad and cost-effective solution to magnify imperceptible high-frequency motion.</em></p>	
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2024-ECCV-EventVFI.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">TimeLens-XL: Real-time Event-based Video Frame Interpolation with Large Motion</span>
	  <br>
	  <a href="https://scholar.google.com/citations?user=JwQLEocAAAAJ&hl=en">Yongrui Ma</a>,
	  <strong>Shi Guo </strong>,
	  <a href="">Yutian Chen</a>,
	  <a href="https://tianfan.info/">Tianfan Xue</a>,
	  <a href="https://www.gujinwei.org/">Jinwei Gu</a>
	  
	  <br>
	  <em>ECCV</em>, 2024
	  <br>
	  <a href="https://openimaginglab.github.io/TimeLens-XL/">Project page</a>
	  /
	  <a href="https://github.com/OpenImagingLab/TimeLens-XL">Code</a>
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2023-SFANet.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	  
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">Spatial-Frequency Attention for Image Denoising</span>
	  <br>
	  <strong>Shi Guo* </strong>,
	  <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=Xii74qQAAAAJ&view_op=list_works&sortby=pubdate">Hongwei Yong*</a>,
	  <a href="https://scholar.google.com/citations?user=q76RnqIAAAAJ&hl=en">Xindong Zhang</a>,
	  <a href="https://scholar.google.com/citations?user=kQUJjQQAAAAJ&hl=en">Jianqi Ma</a>,
	  <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>
	  
	  <br>
	  <em>arXiv</em>, 2023
	  <br>
	  <a href="https://arxiv.org/pdf/2302.13598">Paper</a>
	  <p><em style="color:black;">Effectively enlarge the receptive field.</em></p>	
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2022-2StageAlign.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	  
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">A differentiable two-stage alignment scheme for burst image reconstruction with large shift</span>
	  <br>
	  <strong>Shi Guo </strong>,
	  <a href="">Xi Yang</a>,
	  <a href="https://scholar.google.com/citations?user=kQUJjQQAAAAJ&hl=en">Jianqi Ma</a>,
	  <a href="">Gaofeng Ren</a>,
	  <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>
	  
	  <br>
	  <em>CVPR</em>, 2022
	  <br>
	  <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.pdf">Paper</a>
	  /
	  <a href="https://github.com/GuoShi28/2StageAlign">Code</a>
	  <p><em style="color:black;">Improve restoration performance for images with large shift efficiently.</em></p>	
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2021-GCPNet.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	  
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">Joint denoising and demosaicking with green channel prior for real-world burst images</span>
	  <br>
	  <strong> Shi Guo </strong>,
	  <a href="https://scholar.google.com/citations?user=fCnuU9YAAAAJ&hl=zh-CN">Zhetong Liang</a>,
	  <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>
	  
	  <br>
	  <em>TIP</em>, 2021
	  <br>
	  <a href="https://arxiv.org/pdf/2101.09870">Paper</a>
	  /
	  <a href="https://github.com/GuoShi28/GCP-Net">Code</a>
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:0px;width:20%;vertical-align:top">
	  <div class="one">
		<img src='./assets/img/2019-CBDNet.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 2px;">
	  </div>
	  
	</td>
	<td style="padding:0px;width:80%;vertical-align:top">
		<span class="papertitle">Toward convolutional blind denoising of real photographs</span>
	  <br>
	  <strong> Shi Guo </strong>,
	  <a href=""> Zifei Yan </a>,
	  <a href="https://cszn.github.io/"> Kai Zhang </a>,
	  <a href="https://homepage.hit.edu.cn/wangmengzuo/"> Wangmeng Zuo </a>,
	  <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>
	  <br>
	  <em>CVPR</em>, 2019, (1000+ citation)
	  <br>
	  <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.pdf">Paper</a>
	  /
	  <a href="https://github.com/GuoShi28/CBDNet">Code</a>
	  <p><em style="color:black;">Design noise model for real-world denoising.</em></p>
	</td>
  </tr>

</tbody></table>

<h2>Academic Service and Challenge</h2>
<p>
	Reviewer CVPR, ICCV, ECCV, NeurIPS, ICLR, AAAI<br>
	Reviewer PAMI, TIP, PR 
	
</p>
</div>

</div>
</body>

</html>
